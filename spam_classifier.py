# -*- coding: utf-8 -*-
"""spam_classifier

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VXDcqAIj8RgAD1Qhc_zsQt1o4rbvfWc3
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, accuracy_score
import re

# ==========================================
# 1. Data Loading and Processing
# ==========================================
def load_and_process_data(filepath):
    """Loads the CSV data and splits it into training and testing sets."""
    print(f"Loading data from {filepath}...")
    df = pd.read_csv(filepath)

    # I have Separated features (X) and target (y)
    X = df.drop('is_spam', axis=1)
    y = df['is_spam']

    # My Split data is: 70% training, 30% testing
    # random_state=42 ensures the split is the same every time we run the code
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    return df, X_train, X_test, y_train, y_test

# ==========================================
# 2. Model Training
# ==========================================
def train_model(X_train, y_train):
    """Trains a Logistic Regression model."""
    print("Training Logistic Regression model...")
    model = LogisticRegression()
    model.fit(X_train, y_train)
    return model

def print_coefficients(model, feature_names):
    """Prints the coefficients of the model to show feature importance."""
    coef_df = pd.DataFrame({
        'Feature': feature_names,
        'Coefficient': model.coef_[0]
    })
    print("\nModel Coefficients (Feature Importance):")
    print(coef_df)
    print("-" * 30)
    return coef_df

# ==========================================
# 3. Validation
# ==========================================
def validate_model(model, X_test, y_test):
    """Validates the model on test data and prints accuracy/confusion matrix."""
    y_pred = model.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    cm = confusion_matrix(y_test, y_pred)

    print(f"\nModel Validation Results:")
    print(f"Accuracy: {acc * 100:.2f}%")
    print(f"Confusion Matrix:\n{cm}")
    print("-" * 30)
    return cm

# ==========================================
# 4. Email Checking & Feature Extraction
# ==========================================
# Since the specific spam dictionary wasn't provided, I would define a standard set.
SPAM_KEYWORDS = ['free', 'winner', 'guarantee', 'spam', 'click', 'buy',
                 'offer', 'money', 'prize', 'urgent', 'promotion', 'bank', 'account']

def extract_features(text):
    """
    Parses raw email text to extract the 4 features required by the model:
    [words, links, capital_words, spam_word_count]
    """
    # 1. Words count
    words_list = text.split()
    words_count = len(words_list)

    # 2. Links count (simple regex for http/https or www)
    links_count = len(re.findall(r'http[s]?://|www\.', text))

    # 3. Capital words count (words strictly uppercase, length > 1)
    capital_words_count = sum(1 for w in words_list if w.isupper() and len(w) > 1)

    # 4. Spam word count (check against our keyword list)
    text_lower = text.lower()
    spam_word_count = sum(1 for keyword in SPAM_KEYWORDS if keyword in text_lower)

    return [words_count, links_count, capital_words_count, spam_word_count]

def check_single_email(model, text, label):
    """Extracts features from an email and predicts if it is spam."""
    features = extract_features(text)

    # Reshape for sklearn (1 sample, n features)
    features_array = np.array(features).reshape(1, -1)

    prediction = model.predict(features_array)[0]
    result = "SPAM" if prediction == 1 else "LEGITIMATE"

    print(f"\nChecking {label} Email:")
    print(f"Text snippet: {text.strip()[:60]}...")
    print(f"Extracted Features: {features} (Words, Links, Caps, SpamKeys)")
    print(f"Prediction: {result}")

# ==========================================
# 7. Visualizations
# ==========================================
def generate_visualizations(df, cm, coef_df):
    """Generates and saves the required plots."""
    print("\nGenerating visualizations...")

    # Visualization A: Class Distribution
    plt.figure(figsize=(6, 4))
    sns.countplot(x='is_spam', data=df)
    plt.title('Class Distribution: Legitimate (0) vs Spam (1)')
    plt.xlabel('Class')
    plt.ylabel('Count')
    plt.savefig('class_distribution.png')
    print(" - Saved 'class_distribution.png'")

    # Visualization B: Confusion Matrix Heatmap
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Legitimate', 'Spam'],
                yticklabels=['Legitimate', 'Spam'])
    plt.title('Confusion Matrix Heatmap')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.savefig('confusion_matrix_heatmap.png')
    print(" - Saved 'confusion_matrix_heatmap.png'")

# ==========================================
# Main Execution
# ==========================================
if __name__ == "__main__":
    # File path
    FILE_PATH = 'l_baklaga_89734.csv'

    try:
        # 1. Load Data
        df, X_train, X_test, y_train, y_test = load_and_process_data(FILE_PATH)

        # 2. Train Model
        model = train_model(X_train, y_train)
        coef_df = print_coefficients(model, X_train.columns)

        # 3. Validate
        cm = validate_model(model, X_test, y_test)

        # 7. Visualizations
        generate_visualizations(df, cm, coef_df)

        # 5 & 6. Test Manual Emails

        # Spam Email (High links, caps, and spam keywords)
        spam_email_text = """
        CONGRATULATIONS! You are a WINNER!
        Click here http://www.spamlink.com to claim your FREE PRIZE now.
        This involves huge MONEY and is an URGENT OFFER for you.
        BUY now and get a GIFT.
        """
        check_single_email(model, spam_email_text, "MANUAL SPAM")

        # Legitimate Email (Normal conversation, no links/caps)
        legit_email_text = """
        Hi Dave,
        Can we meet tomorrow at 10 AM to discuss the project updates?
        Let me know if that time works for you.
        Best,
        Sarah
        """
        check_single_email(model, legit_email_text, "MANUAL LEGITIMATE")

        print("\nApplication finished successfully.")

    except FileNotFoundError:
        print(f"Error: The file '{FILE_PATH}' was not found. Please ensure it is in the same directory.")